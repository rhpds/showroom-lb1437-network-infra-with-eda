= Telegraf, Kafka, and YANG

Our goal will be to have our routers able to self-report when BGP has broken, as we simulated in the last section. We'll need to install some software to help us bridge the gap between the routers and Ansible, and we'll need to find out where the data about BGP state is.

[#telegraf]
== Telegraf and Kafka

We will be using a Validated Content Collection in this section.

[NOTE]
====
Ansible validated content is a new set of collections containing pre-built YAML content (such as playbooks or roles) to address the most common automation use cases. You can use Ansible validated content out-of-the-box or as a learning opportunity to develop your skills. It's a trusted starting point to bootstrap your automation: use it, customize it, and learn from it.

https://access.redhat.com/support/articles/ansible-automation-platform-certified-content[Red Hat Customer Portal]
====

We'll be using the validated *network.telemetry* collection to install a Telegraf/Kafka stack in containers, that will translate the telemetry messages coming from the Cisco device and make them consumable by Event-Driven Ansible.

The playbook to do this has been provided for you. In your student workbench, inside the `ansible-cisco-telemetry/playbooks` directory, click on `install_telemetry_stack.yml` and take a look at what it does. You can see that it's using a single role, `network.telemetry.run`, with a couple variables specifying what we want the role to do.

This is a major reason to check out Validated Content - in this situation, we have an easy way to do something complex (in this case, deploy two applications, which will communicate with each other, in containers).

In the terminal, if you are still root, exit back to the student user. If you are in any directory other than ansible-cisco-telemetry, `cd` back to there. Then go ahead and run this playbook:

[source,bash,role=execute]
----
ansible-playbook playbooks/install_telemetry_stack.yml -i inventory
----

Observing the output, we can see that we've deployed something in Docker. Let's look at what's running in Docker:

[source,bash,role=execute]
----
sudo docker ps
----

You should get output that looks like this:

[source,textinfo]
----
CONTAINER ID   IMAGE                             COMMAND                  CREATED          STATUS          PORTS                                                                         NAMES
a16e056d6d15   telegraf:latest                   "/entrypoint.sh -con…"   17 seconds ago   Up 17 seconds   8092/udp, 8125/udp, 8094/tcp, 0.0.0.0:8089->57000/tcp, [::]:8089->57000/tcp   telegraf
bd3888848d03   confluentinc/cp-kafka:7.3.2       "/etc/confluent/dock…"   7 minutes ago    Up 7 minutes    0.0.0.0:9092->9092/tcp, [::]:9092->9092/tcp                                   broker
6ab3f6677c82   confluentinc/cp-zookeeper:7.3.2   "/etc/confluent/dock…"   7 minutes ago    Up 7 minutes    2181/tcp, 2888/tcp, 3888/tcp                                                  zookeeper
----

On the line for Telegraf, we can see `+0.0.0.0:8089->57000/tcp+` which means that we have port 57000 inside the Telegraf container mapped to port 8089 outside of the container.

Similarly, on the line for Kafka we can see `+0.0.0.0:9092->9092/tcp+` which means that we have port 9092 inside the Kafka container mapped to the same port 9092 outside of the container.

The playbook also added some Telegraf configuration that we can look at. In your student workbench, in the file tree on the left, you should now have a `telegraf`` directory that wasn't there before.

The telegraf directory has a `telegraf.conf`` file inside of it. This is mounted to the Telegraf container. Let's look at the `telegraf.conf` file by clicking on it.

Telegraf is a piece of software that takes inputs in one format and outputs them in another, so that's what we're going to be looking for in the configuration file.

In particular, observe this section:

[source,textinfo]
----
[[inputs.cisco_telemetry_mdt]]
transport = "grpc"
service_address = ":57000"
----

Telegraf comes with an input plugin that understands Cisco telemetry messages and it's listening on port 57000, which we know from the Docker output is port 8089 on the outside.

We can also look at this section:

[source,textinfo]
----
[outputs.kafka]
# URLs of kafka brokers
brokers = ["broker:29092"]
topic = "eda"
data_format = "json"
----

Again from the Docker output we know that we can access Kafka on port 9092 from the outside but we also see here that Telegraf will use a different port (29092) to output to it. We can ignore that detail in this situation; what's important is we know that the telemetry messages received by Telegraf will be outputted to Kafka on a topic called `eda`.

Let's get a dedicated Kafka terminal up. listening for any messages coming in on this `eda` topic. In your student workbench, at the top of the terminal, you have a `+` button. Click it, and you should have a new bash terminal come up. You can swap between them on the right. It may be helpful to right-click on your new second terminal, choose Rename, and call it `kafka` since that is all we'll use it for.

In your new terminal, run:
[source,bash,role=execute]
----
sudo docker exec -it broker kafka-console-consumer --bootstrap-server localhost:9092 --topic eda
----

You should get some warnings like:

[source,textinfo]
----
[2025-03-05 22:54:56,148] WARN [Consumer clientId=console-consumer, groupId=console-consumer-14849] Error while fetching metadata with correlation id 2 : {eda=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
----

The `LEADER_NOT_AVAILABLE` message means that no messages have been received on this topic, but we are successfully talking to Kafka regardless, which is what we expect at this stage. Leave this terminal open and switch back to your first/original terminal.

[#yang]
== YANG models

We're going to want to configure our routers for Model-Driven Telemetry in order to send data to Telegraf, but we don't yet know the location of the data we need. We can use Ansible to figure that out.

[NOTE]
====
Yet Another Next-Generation (YANG) was defined in RFC 6020 and has been updated in RFC 7950. The YANG data modeling language was developed by IETF to enable the reuse of data models across equipment from different network vendors. It is widely used by network operators to automate the configuration and monitoring of network devices and define the capabilities of the API.

https://www.cisco.com/c/en/us/products/collateral/switches/catalyst-9300-series-switches/model-driven-telemetry-wp.html[Cisco Model-Driven Telemetry Whitepaper]
====

First, we need to enable YANG, as well as NETCONF (the protocol we need to use to be able to interact with YANG). We can do that by adding a single config line.

[source,bash,role=execute]
----
ssh rtr1
----

[source,bash,role=execute]
----
config terminal
netconf-yang
end
exit
----

Next, in your student workbench, under `ansible-cisco-telemetry/playbooks`, take a look at the playbook `yang_info.yml`.

This playbook targets `rtr1` and has two tasks. The first pulls down a list of all YANG models that the target device says it can support. The second searches that list for a term supplied in the variable `search_for`. That variable's value is set to "bgp". Therefore, what you should see when you run this playbook, is a list of YANG models suported by `rtr1` that are related to configuring or monitoring BGP. Go ahead and run it.

[source,bash,role=execute]
----
ansible-navigator run playbooks/yang_info.yml
----

[TIP]
====
It takes some time for the NETCONF listener to come up from the previous step. If you run the playbook too soon, it may time out or seem to be hanging. You should be able to just try again.
====

The output should look like:
[source]
----
PLAY [Identify YANG modules] ********************************************************************************************************************************************************

TASK [Fetch YANG info] ********************************************************************************************************************************************************
ok: [rtr1]

TASK [Show supported modules] ********************************************************************************************************************************************************
ok: [rtr1] => {
    "yang_info.supported_yang_modules | select('search', search_for, ignorecase=true)": [
        "BGP4-MIB",
        "CISCO-BGP-POLICY-ACCOUNTING-MIB",
        "CISCO-BGP4-MIB",
        "Cisco-IOS-XE-bgp",
        "Cisco-IOS-XE-bgp-actions-rpc",
        "Cisco-IOS-XE-bgp-common-oper",
        "Cisco-IOS-XE-bgp-oper",
        "Cisco-IOS-XE-bgp-route-oper",
        "Cisco-IOS-XE-bgp-rpc",
        "cisco-xe-openconfig-bgp-deviation",
        "cisco-xe-openconfig-bgp-policy-deviation",
        "cisco-xe-openconfig-rib-bgp-ext",
        "openconfig-bgp",
        "openconfig-bgp-common",
        "openconfig-bgp-common-multiprotocol",
[truncated]
----

YANG can be used for both operational data as well as configuration data. We see both kinds of results in this output. For our telemetry purposes, we want YANG modules with "oper" in the name. It looks like `Cisco-IOS-XE-bgp-oper` is what we want. We can take a note of that and move on.

Now that we have the name of the module we want to work with, we need to determine *where* in the module the data we want is. Since YANG modules are expressed in an XML tree format, what we're looking for now will be an "xpath" (short for XML path).

In your student workbench, under `ansible-cisco-telemetry/playbooks`, take a look at the playbook `yang_fetch.yml`.

Like before, this playbook targets `rtr1` and has two tasks. The first pulls down the YANG model file for the model specified in the `model` variable. You can see that's set to "Cisco-IOS-XE-bgp-oper" which we just determined using the previous playbook. The model file will be stored locally for you to work with. The second task reads the model file and produces a tree schema, which we can read more easily than the model file itself.

[NOTE]
====
You may also notice that both of these playbooks override the `ansible_connection` variable to be `ansible.netcommon.netconf`. In the lab inventory, this is set to `ansible.netcommon.network_cli` (SSH), which is the expected way to interact with IOS. The modules in the `ansible.yang` collection are vendor-agnostic and expect to speak NETCONF instead of SSH, so rather than change the Ansible inventory, we are just doing a play-level override.
====

Let's run the playbook.

[source,bash,role=execute]
----
ansible-navigator run playbooks/yang_fetch.yml
----

Once you do this, you should now have a `yang_files` directory that has been created in the same directory as the playbook. Find this in your file tree on the left and expand it. You should see some `.yang` files and a `.tree` file inside.

image::8_yang-files.png[yang files]

Click on `Cisco-IOS-XE-bgp-oper.yang` and look for a line starting with "prefix". You should see:

----
  prefix bgp-ios-xe-oper;
----

That's one part of the information we need. For the other part, let's look in `Cisco-IOS-XE-bgp-oper.tree`.

[source,textinfo]
----
module: Cisco-IOS-XE-bgp-oper
  +--ro bgp-state-data
     +--ro neighbors
     |  +--ro neighbor* [afi-safi vrf-name neighbor-id]
     |     +--ro afi-safi                       bgp-common-ios-xe-oper:afi-safi
     |     +--ro vrf-name                       string
     |     +--ro neighbor-id                    string
     |     +--ro description?                   string
     |     +--ro bgp-version?                   uint16
     |     +--ro link?                          bgp-ios-xe-oper:bgp-link
     |     +--ro up-time?                       string
     |     +--ro last-write?                    string
     |     +--ro last-read?                     string
     |     +--ro installed-prefixes?            uint32
     |     +--ro session-state?                 bgp-ios-xe-oper:bgp-fsm-state
[truncated]
----

We can see the data available in the model displayed as a hierarchichal tree. We can already see that under `bgp-state-data` is a key called `neighbors`, and under that is a key called `neighbor`, and under that is some promising-looking data about BGP state. We'll remember the path `bgp-state-data/neighbors`.
